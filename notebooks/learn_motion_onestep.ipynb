{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn the motion from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import roslib\n",
    "import tf\n",
    "from memmo_utils import *\n",
    "from database import *\n",
    "import os\n",
    "from geometry_msgs.msg import Quaternion, Pose, Point, Vector3\n",
    "from std_msgs.msg import Header, ColorRGBA\n",
    "import rospy\n",
    "import os\n",
    "from mlp.utils.status import Status\n",
    "import mlp.utils.wholebody_result as wb_res\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from transforms3d import axangles\n",
    "from transforms3d import affines, quaternions\n",
    "\n",
    "#from pykdl_utils.kdl_parser import kdl_tree_from_urdf_model\n",
    "#from pykdl_utils.kdl_kinematics import KDLKinematics\n",
    "\n",
    "\n",
    "from regression import *\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Instruction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.system('roslaunch talos_description upload.launch &') # upload talos urdf to ros_param server\n",
    "os.system('rosrun robot_state_publisher robot_state_publisher &')\n",
    "os.system('rosrun rviz rviz  &') #change to rviz config locations\n",
    "#os.system('rosrun rviz rviz -d ./rviz_config.rviz &') #change to rviz config locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Robot using URDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import roslib; roslib.load_manifest('urdfdom_py')\n",
    "from urdf_parser_py.urdf import URDF\n",
    "robot = URDF.from_parameter_server()\n",
    "clear_output()\n",
    "\n",
    "tree = kdl_tree_from_urdf_model(robot)\n",
    "\n",
    "left_foot = KDLKinematics(robot, 'base_link', 'left_sole_link')\n",
    "right_foot = KDLKinematics(robot, 'base_link', 'right_sole_link')\n",
    "\n",
    "q = left_foot.random_joint_angles()\n",
    "pose = left_foot.forward(q) # forward kinematics (returns homogeneous 4x4 numpy.mat)\n",
    "q_ik = left_foot.inverse(pose, q+0.3) # inverse kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = Visual()\n",
    "viz.rate = rospy.Rate(1000)\n",
    "\n",
    "foot_marker = RvizMarker('foot_marker', 5, Marker.CUBE, 4)\n",
    "colors = [ColorRGBA(0.0, 1.0, 0.0, 0.7), ColorRGBA(0.0, 0.0, 1.0, 0.7)] + [ColorRGBA(1.0, 0.0, 0.0, 0.9)]*2\n",
    "foot_marker.set_color(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_CAT = 'talos_moveEffector_flat'\n",
    "#FILE_CAT = 'talos_circle'\n",
    "#FILE_CAT = 'talos_circle_oriented'\n",
    "ROOT_PROCESSED = '/media/teguh/Data/MEMMO Dataset/processed_data/' + FILE_CAT + '/'\n",
    "ROOT_CROCS = '/media/teguh/Data/MEMMO Dataset/crocs_data/' + FILE_CAT + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_crocs = False\n",
    "if use_crocs:\n",
    "    f = open(ROOT_CROCS + '/data_left_right.pkl', 'rb')\n",
    "else:\n",
    "    f = open(ROOT_PROCESSED + '/data_left_right.pkl', 'rb')\n",
    "data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "trajs = dict()\n",
    "vel_trajs = dict()\n",
    "x_inputs = dict()\n",
    "foot_poses = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_type = 'contact'#'root'#\n",
    "num_desired = 600\n",
    "keys = ['left','right']\n",
    "num_data = dict()\n",
    "for key in keys:\n",
    "    trajs[key] = np.array(data[key]['trajs'])[:num_desired]\n",
    "    vel_trajs[key] = np.array(data[key]['vel_trajs'])[:num_desired]\n",
    "    if goal_type == 'contact':\n",
    "        x_inputs[key] = np.array(data[key]['x_inputs'])[:num_desired]\n",
    "    elif goal_type == 'root':\n",
    "        x_inputs[key] = np.array(data[key]['x_inputs_root'])[:num_desired]\n",
    "    foot_poses[key] = data[key]['foot_poses'][:num_desired]\n",
    "    num_data[key] = len(foot_poses[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the control trajectory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_trajs = dict()\n",
    "for key in keys:\n",
    "    if use_crocs:\n",
    "        raw_trajs = data[key]['u_trajs']\n",
    "        for i in range(len(raw_trajs)):\n",
    "            raw_trajs[i][59] = raw_trajs[i][58]\n",
    "        u_trajs[key] = np.array(raw_trajs)\n",
    "    else:\n",
    "        u_trajs[key] = np.array(data[key]['u_trajs'])[:num_desired]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_crocs:\n",
    "    del_indexes = dict()\n",
    "    for key in keys:\n",
    "        del_indexes[key] = []\n",
    "        for i in range(num_data[key]):\n",
    "            if np.max(np.abs(trajs[key][i])) > 1e2:\n",
    "                del_indexes[key] += [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the error data "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print del_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_crocs:\n",
    "    for key in keys:\n",
    "        trajs[key] = np.delete(trajs[key],del_indexes[key],axis=0)\n",
    "        x_inputs[key] = np.delete(x_inputs[key],del_indexes[key],axis=0)\n",
    "        foot_poses[key] = np.delete(foot_poses[key],del_indexes[key],axis=0)\n",
    "        vel_trajs[key] = np.delete(vel_trajs[key],del_indexes[key],axis=0)\n",
    "        u_trajs[key] = np.delete(u_trajs[key],del_indexes[key],axis=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsample to the original time intervals (1ms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_crocs:\n",
    "    original_T = 3351\n",
    "    #original_T = 4351\n",
    "\n",
    "    if use_crocs:\n",
    "        new_trajs = dict()\n",
    "        new_vel_trajs = dict()\n",
    "        new_u_trajs = dict()\n",
    "        for key in keys:\n",
    "            new_trajs[key] = []\n",
    "            new_vel_trajs[key] = []\n",
    "            new_u_trajs[key] = []\n",
    "            for i in range(len(trajs[key])):\n",
    "                traj = trajs[key][i]\n",
    "                new_traj = subsample(traj, original_T)\n",
    "                new_trajs[key].append(new_traj)\n",
    "\n",
    "                vel_traj = vel_trajs[key][i]\n",
    "                new_vel_traj = subsample(vel_traj, original_T)\n",
    "                new_vel_trajs[key].append(new_vel_traj)\n",
    "\n",
    "                u_traj = u_trajs[key][i]\n",
    "                new_u_traj = subsample(u_traj, original_T)\n",
    "                new_u_trajs[key].append(new_u_traj)\n",
    "\n",
    "            new_trajs[key] = np.array(new_trajs[key])\n",
    "            new_vel_trajs[key] = np.array(new_vel_trajs[key])\n",
    "            new_u_trajs[key] = np.array(new_u_trajs[key])\n",
    "\n",
    "        trajs = new_trajs\n",
    "        vel_trajs = new_vel_trajs\n",
    "        u_trajs = new_u_trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.set_rate(1000)\n",
    "\n",
    "key = 'left'\n",
    "for i in range(1):\n",
    "    foot_marker.publish(x_inputs[key][i].reshape(-1,3))\n",
    "    viz.vis_traj(trajs[key][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define RBF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestep = 3351#trajs['left'].shape[1]\n",
    "rbf_num = 60\n",
    "Phi = define_RBF(dof=39, nbStates = rbf_num, offset = 200, width = 60, T = timestep)\n",
    "%matplotlib qt\n",
    "plt.plot(Phi)\n",
    "plt.savefig('/home/rli/git/presentations/MEMMO/2019_sab_meeting/figures/rbf.png')\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply RBF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_RBF(trajs, Phi, rcond=0.0001):\n",
    "    w_trajs = []\n",
    "    for traj in trajs:\n",
    "        w,_,_,_ = np.linalg.lstsq(Phi, traj, rcond=0.0001)\n",
    "        w_trajs.append(w.flatten())\n",
    "    return np.array(w_trajs)\n",
    "    \n",
    "def inverse_transform(w_pca, pca, Phi, rbf_num):\n",
    "    w = pca.inverse_transform(w_pca)\n",
    "    w = w.reshape(rbf_num,-1)\n",
    "    traj = np.dot(Phi,w)\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_trajs = dict()\n",
    "for key in keys:\n",
    "    w_trajs[key] = []\n",
    "    for traj in trajs[key]:\n",
    "        w,_,_,_ = np.linalg.lstsq(Phi, traj, rcond=0.0001)\n",
    "        w_trajs[key].append(w.flatten())\n",
    "    w_trajs[key] = np.array(w_trajs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_trajs = dict()\n",
    "w_vel_trajs = dict()\n",
    "w_u_trajs = dict()\n",
    "\n",
    "for key in keys:\n",
    "    w_trajs[key] = apply_RBF(trajs[key], Phi)\n",
    "    if use_crocs:\n",
    "        w_vel_trajs[key] = apply_RBF(vel_trajs[key], Phi)\n",
    "        w_u_trajs[key] = apply_RBF(u_trajs[key], Phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the approximated trajectories "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "key = 'right'\n",
    "traj = trajs[key][np.random.randint(len(trajs[key]))]\n",
    "w,_,_,_ = np.linalg.lstsq(Phi, traj, rcond=0.0001)\n",
    "traj_rec = np.dot(Phi,w)\n",
    "for i in range(3):\n",
    "    plt.plot(traj[:,i], '*')\n",
    "    plt.plot(traj_rec[:,i], '-')\n",
    "    plt.show()\n",
    "    raw_input()\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "key = 'right'\n",
    "vel_traj = vel_trajs[key][np.random.randint(len(vel_trajs[key]))]\n",
    "w,_,_,_ = np.linalg.lstsq(Phi, vel_traj, rcond=0.0001)\n",
    "vel_traj_rec = np.dot(Phi,w)\n",
    "for i in range(3):\n",
    "    plt.plot(vel_traj[:,i], '*')\n",
    "    plt.plot(vel_traj_rec[:,i], '-')\n",
    "    plt.show()\n",
    "    raw_input()\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "key = 'right'\n",
    "u_traj = u_trajs[key][np.random.randint(len(u_trajs[key]))]\n",
    "w,_,_,_ = np.linalg.lstsq(Phi, u_traj, rcond=0.0001)\n",
    "u_traj_rec = np.dot(Phi,w)\n",
    "for i in range(3):\n",
    "    plt.plot(u_traj[:,i], '*')\n",
    "    plt.plot(u_traj_rec[:,i], '-')\n",
    "    plt.show()\n",
    "    raw_input()\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try PCA decomposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs['left'].shape\n",
    "w_trajs2 = dict()\n",
    "w_trajs2['left'] = trajs['left'].reshape(600,-1)\n",
    "w_trajs2['right'] = trajs['right'].reshape(600,-1)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)\n",
    "import time\n",
    "tic = time.time()\n",
    "w_trajs_pca = dict()\n",
    "w_trajs_pca['left'] = pca.fit_transform(w_trajs2['left'])\n",
    "w_trajs_pca['right'] = pca.fit_transform(w_trajs2['right'])\n",
    "toc = time.time()\n",
    "print toc-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "num_pca_comp = 60\n",
    "\n",
    "w_trajs_pca = dict()\n",
    "pca = dict()\n",
    "\n",
    "w_vel_trajs_pca = dict()\n",
    "pca_vel = dict()\n",
    "\n",
    "w_u_trajs_pca = dict()\n",
    "pca_u = dict()\n",
    "\n",
    "for key in keys:\n",
    "    pca[key] = PCA(n_components=num_pca_comp)\n",
    "    w_trajs_pca[key] = pca[key].fit_transform(w_trajs[key])\n",
    "    \n",
    "    if use_crocs:\n",
    "        pca_vel[key] = PCA(n_components=num_pca_comp)\n",
    "        w_vel_trajs_pca[key] = pca_vel[key].fit_transform(w_vel_trajs[key])\n",
    "\n",
    "        pca_u[key] = PCA(n_components=num_pca_comp)\n",
    "        w_u_trajs_pca[key] = pca_u[key].fit_transform(w_u_trajs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'left'\n",
    "for i in range(10):\n",
    "    w_pca = w_trajs_pca[key][i]\n",
    "    w = pca[key].inverse_transform(w_pca)\n",
    "    w = w.reshape(60,-1)\n",
    "    #traj = w.reshape(3351,-1)\n",
    "    traj = np.dot(Phi,w)\n",
    "    foot_marker.publish(foot_poses[key][i])\n",
    "    viz.vis_traj(traj)\n",
    "    raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'left'\n",
    "for i in range(10):\n",
    "    w_pca = w_trajs_pca[i]\n",
    "    w = pca.inverse_transform(w_pca)\n",
    "    traj = w.reshape(3351,-1)\n",
    "    foot_marker.publish(foot_poses[key][i])\n",
    "    viz.vis_traj(traj)\n",
    "    raw_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning from Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regression import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bgmr = dict()\n",
    "for key in keys:\n",
    "    bgmr[key] = DP_GLM_Regressor(n_components=10,n_init=5)\n",
    "    bgmr[key].fit(x_inputs[key], w_trajs_pca[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inputs_train = dict()\n",
    "x_inputs_test = dict()\n",
    "y_train = dict()\n",
    "y_test = dict()\n",
    "\n",
    "y_vel_train = dict()\n",
    "y_vel_test = dict()\n",
    "\n",
    "y_u_train = dict()\n",
    "y_u_test = dict()\n",
    "\n",
    "for key in keys:\n",
    "    x_inputs_train[key], x_inputs_test[key], y_train[key], y_test[key] = train_test_split(x_inputs[key],w_trajs_pca[key], test_size = 0.1666, random_state=1)\n",
    "    if use_crocs:\n",
    "        _,_, y_vel_train[key], y_vel_test[key] = train_test_split(x_inputs[key],w_vel_trajs_pca[key], test_size = 0.1666, random_state=1)\n",
    "        _,_, y_u_train[key], y_u_test[key] = train_test_split(x_inputs[key],w_u_trajs_pca[key], test_size = 0.1666, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr = dict()\n",
    "nn = dict()\n",
    "gmr = dict()\n",
    "\n",
    "gpr_vel = dict()\n",
    "gpr_u = dict()\n",
    "\n",
    "nn_vel = dict()\n",
    "nn_u = dict()\n",
    "\n",
    "\n",
    "for key in keys:\n",
    "    gpr[key] = GPy_Regressor(dim_input=x_inputs_train[key].shape[1],is_transform=True)\n",
    "    gpr[key].pca = pca[key]\n",
    "    gpr[key].fit(x_inputs_train[key], y_train[key],num_restarts=3)\n",
    "    nn[key] = NN_Regressor(K = 1)\n",
    "    nn[key].fit(x_inputs_train[key], y_train[key])\n",
    "    nn[key].pca = pca[key]\n",
    "    #gmr[key] = BGMR_Regressor(n_components=10,n_init = 10)\n",
    "    #gmr[key].fit(x_inputs_train[key], y_train[key],init_type='random')\n",
    "    #gmr[key].pca = pca[key]\n",
    "\n",
    "    if use_crocs:\n",
    "        gpr_vel[key] = GPy_Regressor(dim_input=x_inputs_train[key].shape[1],is_transform=True)\n",
    "        gpr_vel[key].pca = pca_vel[key]\n",
    "        gpr_vel[key].fit(x_inputs_train[key], y_vel_train[key],num_restarts=3)\n",
    "\n",
    "        nn_vel[key] = NN_Regressor(K = 1)\n",
    "        nn_vel[key].pca = pca_vel[key]\n",
    "        nn_vel[key].fit(x_inputs_train[key], y_vel_train[key])\n",
    "\n",
    "        gpr_u[key] = GPy_Regressor(dim_input=x_inputs_train[key].shape[1],is_transform=True)\n",
    "        gpr_u[key].pca = pca_u[key]\n",
    "        gpr_u[key].fit(x_inputs_train[key], y_u_train[key],num_restarts=3)\n",
    "\n",
    "        nn_u[key] = NN_Regressor(K = 1)\n",
    "        nn_u[key].pca = pca_u[key]\n",
    "        nn_u[key].fit(x_inputs_train[key], y_u_train[key])\n",
    "\n",
    "clear_output()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = dict()\n",
    "\n",
    "for key in keys:\n",
    "    nn[key] = NN_Regressor(K = 1)\n",
    "    nn[key].fit(x_inputs_train[key], y_train[key])\n",
    "    nn[key].pca = pca[key]\n",
    "\n",
    "clear_output()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = dict()\n",
    "functions['gpr'] = gpr\n",
    "functions['nn'] = nn\n",
    "functions['gmr'] = gmr\n",
    "\n",
    "if use_crocs:\n",
    "    functions['gpr_vel'] = gpr_vel\n",
    "    functions['gpr_u'] = gpr_u\n",
    "    f = open(ROOT_CROCS + '/functions.pkl', 'wb')\n",
    "else:\n",
    "    f = open(ROOT_CROCS + '/functions_A.pkl', 'wb')\n",
    "pickle.dump(functions, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load function approximators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_CAT = 'talos_moveEffector_flat'\n",
    "#FILE_CAT = 'talos_circle'\n",
    "#FILE_CAT = 'talos_circle_oriented'\n",
    "ROOT_PROCESSED = '/media/teguh/Data/MEMMO Dataset/processed_data/' + FILE_CAT + '/'\n",
    "ROOT_CROCS = '/media/teguh/Data/MEMMO Dataset/crocs_data/' + FILE_CAT + '/'\n",
    "#based on database B\n",
    "f = open(ROOT_CROCS + '/functions.pkl', 'rb')\n",
    "functions = pickle.load(f)\n",
    "f.close()\n",
    "gpr = functions['gpr']\n",
    "nn = functions['nn']\n",
    "gmr = functions['gmr'] \n",
    "gpr_vel = functions['gpr_vel']\n",
    "gpr_u = functions['gpr_u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on database A\n",
    "f = open(ROOT_CROCS + '/functions_A.pkl', 'rb')\n",
    "functions_A = pickle.load(f)\n",
    "f.close()\n",
    "gpr_A = functions_A['gpr']\n",
    "nn_A = functions_A['nn']\n",
    "gmr_A = functions_A['gmr'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff_pose(pose_true, pose_pred):\n",
    "    diff = 0.\n",
    "    for i in range(len(pose_true)):\n",
    "        diff += np.linalg.norm(pose_true[i] - pose_pred[i])\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate time\n",
    "gmr_time = []\n",
    "gpr_time = []\n",
    "nn_time = []\n",
    "\n",
    "for key in keys:\n",
    "    for i in range(len(x_inputs_test[key])):\n",
    "        x = x_inputs_test[key][i:i+1,:]\n",
    "        y_true = y_test[key][i:i+1,:]\n",
    "        \n",
    "        tic = time.time()\n",
    "        y_pred,_ = gpr[key].predict(x)\n",
    "        traj_pred = inverse_transform(y_pred, pca[key], Phi, rbf_num)\n",
    "        toc = time.time()\n",
    "        gpr_time.append(toc-tic)\n",
    "        \n",
    "        tic = time.time()\n",
    "        y_pred,_ = nn[key].predict(x)\n",
    "        traj_pred = inverse_transform(y_pred, pca[key], Phi, rbf_num)\n",
    "        toc = time.time()\n",
    "        nn_time.append(toc-tic)\n",
    "        \n",
    "        tic = time.time()\n",
    "        y_pred,_ = gmr[key].predict(x)\n",
    "        traj_pred = inverse_transform(y_pred, pca[key], Phi, rbf_num)\n",
    "        toc = time.time()\n",
    "        gmr_time.append(toc-tic)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.mean(gpr_time), np.mean(gmr_time),np.mean(nn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmr_err = []\n",
    "gpr_err = []\n",
    "nn_err = []\n",
    "\n",
    "gmr_foot_err = []\n",
    "gpr_foot_err = []\n",
    "nn_foot_err = []\n",
    "\n",
    "#gpr_vel_err = []\n",
    "#gpr_u_err = []\n",
    "\n",
    "#nn_vel_err = []\n",
    "#nn_u_err = []\n",
    "\n",
    "\n",
    "for key in keys:\n",
    "    for i in range(len(x_inputs_test[key])):\n",
    "        x = x_inputs_test[key][i:i+1,:]\n",
    "        y_true = y_test[key][i:i+1,:]\n",
    "        traj_true = inverse_transform(y_true, pca[key], Phi, rbf_num)\n",
    "        left_pose_init,right_pose_init = calc_foot_pose(traj_true[0],left_foot, right_foot, pose_type = '2D')\n",
    "        left_pose_goal,right_pose_goal = calc_foot_pose(traj_true[-1],left_foot, right_foot, pose_type = '2D')\n",
    "        pose_true = [left_pose_init,right_pose_init,left_pose_goal,right_pose_goal ]\n",
    "        \n",
    "        \n",
    "        y_pred,_ = gpr[key].predict(x)\n",
    "        traj_pred = inverse_transform(y_pred, pca[key], Phi, rbf_num)\n",
    "        #gpr_err.append(np.linalg.norm(y_true-y_pred))\n",
    "        gpr_err.append(np.linalg.norm(traj_true.flatten()-traj_pred.flatten()))\n",
    "        left_pose_init_pred,right_pose_init_pred = calc_foot_pose(traj_pred[0],left_foot, right_foot, pose_type = '2D')\n",
    "        left_pose_goal_pred,right_pose_goal_pred = calc_foot_pose(traj_pred[-1],left_foot, right_foot, pose_type = '2D')\n",
    "        pose_pred = [left_pose_init_pred,right_pose_init_pred,left_pose_goal_pred,right_pose_goal_pred ]\n",
    "        gpr_foot_err.append(calc_diff_pose(pose_true, pose_pred))\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_pred,_ = nn[key].predict(x)\n",
    "        traj_pred = inverse_transform(y_pred, pca[key], Phi, rbf_num)\n",
    "        #nn_err.append(np.linalg.norm(y_true-y_pred))\n",
    "        nn_err.append(np.linalg.norm(traj_true.flatten()-traj_pred.flatten()))\n",
    "        left_pose_init_pred,right_pose_init_pred = calc_foot_pose(traj_pred[0],left_foot, right_foot, pose_type = '2D')\n",
    "        left_pose_goal_pred,right_pose_goal_pred = calc_foot_pose(traj_pred[-1],left_foot, right_foot, pose_type = '2D')\n",
    "        pose_pred = [left_pose_init_pred,right_pose_init_pred,left_pose_goal_pred,right_pose_goal_pred ]\n",
    "        nn_foot_err.append(calc_diff_pose(pose_true, pose_pred))\n",
    "\n",
    "        \n",
    "        y_pred,_ = gmr[key].predict(x.flatten())\n",
    "        traj_pred = inverse_transform(y_pred, pca[key], Phi, rbf_num)\n",
    "        #gmr_err.append(np.linalg.norm(y_true-y_pred))\n",
    "        gmr_err.append(np.linalg.norm(traj_true.flatten()-traj_pred.flatten()))\n",
    "        left_pose_init_pred,right_pose_init_pred = calc_foot_pose(traj_pred[0],left_foot, right_foot, pose_type = '2D')\n",
    "        left_pose_goal_pred,right_pose_goal_pred = calc_foot_pose(traj_pred[-1],left_foot, right_foot, pose_type = '2D')\n",
    "        pose_pred = [left_pose_init_pred,right_pose_init_pred,left_pose_goal_pred,right_pose_goal_pred ]\n",
    "        gmr_foot_err.append(calc_diff_pose(pose_true, pose_pred))\n",
    "        \n",
    "        '''\n",
    "        if use_crocs:\n",
    "            y_vel_true = y_vel_test[key][i:i+1,:]\n",
    "            y_vel_pred,_ = gpr_vel[key].predict(x)\n",
    "            gpr_vel_err.append(np.linalg.norm(y_vel_true-y_vel_pred))\n",
    "\n",
    "            y_vel_pred,_ = nn_vel[key].predict(x)\n",
    "            nn_vel_err.append(np.linalg.norm(y_vel_true-y_vel_pred))\n",
    "\n",
    "            y_u_true = y_u_test[key][i:i+1,:]\n",
    "            y_u_pred,_ = gpr_u[key].predict(x)\n",
    "            gpr_u_err.append(np.linalg.norm(y_u_true-y_u_pred))\n",
    "\n",
    "            y_u_pred,_ = nn_u[key].predict(x)\n",
    "            nn_u_err.append(np.linalg.norm(y_u_true-y_u_pred))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"GPR & \\t {0:.2f} $\\\\pm$ {1:.2f} \\t & {2:.2f} $\\\\pm$ {3:.2f}\".format(np.mean(gpr_err), np.std(gpr_err), np.mean(gpr_foot_err), np.std(gpr_foot_err))\n",
    "print \"GMR & \\t {0:.2f} $\\\\pm$ {1:.2f} \\t & {2:.2f} $\\\\pm$ {3:.2f}\".format(np.mean(gmr_err), np.std(gmr_err), np.mean(gmr_foot_err), np.std(gmr_foot_err))\n",
    "print \"$k$-NN & \\t {0:.2f} $\\\\pm$ {1:.2f} \\t & {2:.2f} $\\\\pm$ {3:.2f}\".format(np.mean(nn_err), np.std(nn_err), np.mean(nn_foot_err), np.std(nn_foot_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_crocs: \n",
    "    print np.mean(gpr_vel_err),np.mean(nn_vel_err) \n",
    "    print np.std(gpr_vel_err),np.std(nn_vel_err)\n",
    "\n",
    "    print np.mean(gpr_u_err),np.mean(nn_u_err) \n",
    "    print np.std(gpr_u_err),np.std(nn_u_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = dict()\n",
    "for key in keys:\n",
    "    gmm[key] = GaussianMixture(n_components=30, n_init = 3) \n",
    "    gmm[key].fit(x_inputs[key])\n",
    "\n",
    "viz.set_rate(1000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = np.array([[-0.1196,  0.1381,  0.1231,  0.2173, -0.1421,  0.2453,  0.3054,\n",
    "         0.1305, -0.1587]])\n",
    "key = 'left'\n",
    "\n",
    "x = np.array([[ 0.2911,  0.1391,  0.2786, -0.1895, -0.0433, -0.3054,  0.2855,\n",
    "        -0.0931,  0.1761]])\n",
    "key = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [0, 3, 7, 8, 9, 12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['left', 'right']\n",
    "\n",
    "nn_A = dict()\n",
    "for key in keys:\n",
    "    x = gpr_A[key].gp.X\n",
    "    y = gpr_A[key].gp.Y\n",
    "    nn_A[key] = NN_Regressor()\n",
    "    nn_A[key].fit(x,y)\n",
    "    nn_A[key].pca = gpr_A[key].pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [2,4,6,8,11,14,20,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_FILE_NAME = \"/home/teguh/git/publications/memmo_icra_2020/videos/gmr_\"\n",
    "key = 'right'\n",
    "fig_index = 0\n",
    "for i in (indexes):\n",
    "#for i in range(50):  \n",
    "    print i\n",
    "    if i%2 == 0:\n",
    "        key = 'left'\n",
    "    else:\n",
    "        key = 'right'\n",
    "    x = x_inputs_test[key][np.random.randint(x_inputs_test[key].shape[0])][None,:]\n",
    "    #x = x_inputs_test[key][i][None,:]\n",
    "    \n",
    "    #x,_ = gmm[key].sample()\n",
    "    func = gpr\n",
    "\n",
    "    #w_pca,cov = gmr[key].predict(x.flatten())\n",
    "    w_pca,cov = func[key].predict(x)\n",
    "    w_pca = mvn(mean=w_pca.flatten(),cov=0.01*np.eye(w_pca.shape[1])).rvs()\n",
    "    w_pca[15:] *=0.\n",
    "    print w_pca\n",
    "    #print cov\n",
    "    w = func[key].pca.inverse_transform(w_pca)\n",
    "    #w = w.reshape(rbf_num,-1)\n",
    "    #traj = np.dot(Phi,w)\n",
    "    traj = w.reshape(3351,-1)\n",
    "    if goal_type == 'contact':\n",
    "        foot_marker.publish(x.reshape(-1,3))    \n",
    "    elif goal_type == 'root':\n",
    "        foot_marker.publish(x[0,0:6].reshape(-1,3))    \n",
    "        viz.br.sendTransform(traj[0,0:3], normalize(traj[0,3:7]),\n",
    "         rospy.Time.now(),\n",
    "         \"init\",\n",
    "         \"world\"\n",
    "         )\n",
    "        viz.br.sendTransform(x[0,6:9], normalize(x[0,9:13]),\n",
    "                 rospy.Time.now(),\n",
    "                 \"goal\",\n",
    "                 \"world\"\n",
    "                 )\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    viz.set_dof(traj[0])\n",
    "    time.sleep(0.2)\n",
    "    for j,index in enumerate(np.arange(0,3350,50)):\n",
    "        viz.set_dof(traj[index])\n",
    "        time.sleep(0.04)\n",
    "        #ave_screenshot(200,200,700,700, FIG_FILE_NAME +  str(fig_index) + '.png') \n",
    "        fig_index +=1\n",
    "    for k in range(20):\n",
    "        #save_screenshot(200,200,700,700, FIG_FILE_NAME  +  str(fig_index)  + '.png') \n",
    "        fig_index +=1\n",
    "    '''\n",
    "    \n",
    "    viz.vis_traj(traj)\n",
    "    #dec = raw_input()\n",
    "    #if dec == 'y':\n",
    "    #    indexes += [i]\n",
    "    #key = toggle_key(key)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.set_dof(traj[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,index in enumerate(np.arange(0,3350,50)):\n",
    "    viz.set_dof(traj[index])\n",
    "    time.sleep(0.04)\n",
    "    save_screenshot(200,200,700,700, FIG_FILE_NAME + '_' + str(i)+ str(j) + '.png') \n",
    "\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('ffmpeg -r 25 -start_number 0 -i /home/teguh/git/publications/memmo_icra_2020/videos/gpr_%d.png -c:v libx264 -r 30 -pix_fmt yuv420p /home/teguh/git/publications/memmo_icra_2020/videos/gpr.mp4')\n",
    "\n",
    "os.system('ffmpeg -r 25 -start_number 0 -i /home/teguh/git/publications/memmo_icra_2020/videos/gmr_%d.png -c:v libx264 -r 30 -pix_fmt yuv420p /home/teguh/git/publications/memmo_icra_2020/videos/gmr.mp4')\n",
    "\n",
    "os.system('ffmpeg -r 25 -start_number 0 -i /home/teguh/git/publications/memmo_icra_2020/videos/nn_%d.png -c:v libx264 -r 30 -pix_fmt yuv420p /home/teguh/git/publications/memmo_icra_2020/videos/nn.mp4')\n",
    "\n",
    "os.system('ffmpeg -r 25 -start_number 0 -i /home/teguh/git/publications/memmo_icra_2020/videos/gpra_%d.png -c:v libx264 -r 30 -pix_fmt yuv420p /home/teguh/git/publications/memmo_icra_2020/videos/gpr_A.mp4')\n",
    "\n",
    "os.system('ffmpeg -r 25 -start_number 0 -i /home/teguh/git/publications/memmo_icra_2020/videos/gmra_%d.png -c:v libx264 -r 30 -pix_fmt yuv420p /home/teguh/git/publications/memmo_icra_2020/videos/gmr_A.mp4')\n",
    "\n",
    "os.system('ffmpeg -r 25 -start_number 0 -i /home/teguh/git/publications/memmo_icra_2020/videos/nna_%d.png -c:v libx264 -r 30 -pix_fmt yuv420p /home/teguh/git/publications/memmo_icra_2020/videos/nn_A.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the distribution of trajectories "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.stats import multivariate_normal as mvn\n",
    "#traj_dist = mvn(w_pca[0], 100*cov[0])\n",
    "traj_dist = mvn(w_pca, 25*cov)\n",
    "\n",
    "traj_samples = []\n",
    "for i in range(20):\n",
    "    w_pca_sample = traj_dist.rvs()\n",
    "    w = pca[key].inverse_transform(w_pca_sample)\n",
    "    w = w.reshape(rbf_num,-1)\n",
    "    traj_samples.append(np.dot(Phi,w))\n",
    "    \n",
    "traj_samples = np.array(traj_samples)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for traj in traj_samples:\n",
    "    #iz.set_dof(traj[2100])\n",
    "    viz.vis_traj(traj)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "traj_samples.shape\n",
    "\n",
    "plt.plot(traj_samples[:,2500,-10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmstart crocoddyl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading function approximators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on database B\n",
    "f = open(ROOT_CROCS + '/functions.pkl', 'rb')\n",
    "functions = pickle.load(f)\n",
    "f.close()\n",
    "gpr = functions['gpr']\n",
    "nn = functions['nn']\n",
    "gmr = functions['gmr'] \n",
    "\n",
    "gpr_vel = functions['gpr_vel']\n",
    "gpr_u = functions['gpr_u']\n",
    "\n",
    "#based on database A\n",
    "f = open(ROOT_CROCS + '/functions_A.pkl', 'rb')\n",
    "functions_A = pickle.load(f)\n",
    "f.close()\n",
    "gpr_A = functions_A['gpr']\n",
    "nn_A = functions_A['nn']\n",
    "gmr_A = functions_A['gmr'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_foot_T(x, move = 'left'):\n",
    "    #calculate the footstep transformation matrix based on the input x\n",
    "    #x is defined as: [left_foot, right_foot, 'foot_to_move']\n",
    "    x = x.reshape(-1,3)\n",
    "    Ts = []\n",
    "    for x_i in x:\n",
    "        T = PosetoMat(x_i)\n",
    "        Ts.append(T)\n",
    "    \n",
    "    if move == 'left':\n",
    "        T_lefts = [Ts[0], None, Ts[2]]\n",
    "        T_rights = [Ts[1]]*3\n",
    "    else:\n",
    "        T_rights = [Ts[1], None, Ts[2]]\n",
    "        T_lefts = [Ts[0]]*3\n",
    "        \n",
    "    return T_lefts, T_rights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.random.rand() < 0.5:\n",
    "    key = 'left'\n",
    "else:\n",
    "    key = 'right'\n",
    "x,_ = gmm[key].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_lefts, T_rights = calc_foot_T(x,move=key)\n",
    "foot_marker.publish(x.reshape(-1,3))\n",
    "\n",
    "#predict the trajectory\n",
    "w_pca,cov = gpr[key].predict(x)\n",
    "w = gpr[key].pca.inverse_transform(w_pca)\n",
    "w = w.reshape(rbf_num,-1)\n",
    "traj = np.dot(Phi,w)\n",
    "\n",
    "#predict the velocity trajectory\n",
    "w_pca,cov = gpr_vel[key].predict(x)\n",
    "w = gpr_vel[key].pca.inverse_transform(w_pca)\n",
    "w = w.reshape(rbf_num,-1)\n",
    "vel_traj = np.dot(Phi,w)\n",
    "\n",
    "#predict the control trajectory\n",
    "w_pca,cov = gpr_u[key].predict(x)\n",
    "w = gpr_u[key].pca.inverse_transform(w_pca)\n",
    "w = w.reshape(rbf_num,-1)\n",
    "u_traj = np.dot(Phi,w)\n",
    "\n",
    "\n",
    "#visualize\n",
    "viz.set_rate(1000)\n",
    "#viz.vis_traj(traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create phases"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_phases = []\n",
    "data_phases.append(np.arange(0,38))\n",
    "data_phases.append(np.arange(38,73))\n",
    "data_phases.append(np.arange(73,110))\n",
    "delta_t = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_phases = []\n",
    "data_phases.append(np.arange(0,25))\n",
    "data_phases.append(np.arange(25,60))\n",
    "data_phases.append(np.arange(60,85))\n",
    "delta_t = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_phases_ori = [data_phases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsample the trajectories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = traj.shape[0]\n",
    "intervals = np.concatenate([np.arange(0,T,40),[T-1]])\n",
    "T_new = len(intervals)\n",
    "traj = traj[intervals]\n",
    "#vel_traj = np.zeros((traj.shape[0], 38))\n",
    "#u_traj = np.zeros((traj.shape[0], 32))\n",
    "\n",
    "#for visualization\n",
    "viz.set_rate(25)\n",
    "raw_traj = traj.copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vel_traj = np.zeros((traj.shape[0], 38))\n",
    "#u_traj = np.zeros((traj.shape[0], 32))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "viz.vis_traj(raw_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store in Crocoddyl format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = store_for_crocoddyl(traj, vel_traj, u_traj, T_lefts, T_rights, data_phases, delta_t)\n",
    "pickle.dump(phases,open('data_teguh_3.txt','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Crocoddyl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memmo_utils import *\n",
    "from crocoddyl import loadTalos\n",
    "from croc_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT = loadTalos('/opt/openrobots/share/example-robot-data')\n",
    "problem, xs, us, ts = define_croc_problem(ROBOT,'data_teguh_3.txt', num_phases=3, is_warmstart=True)\n",
    "clear_output()\n",
    "\n",
    "solver = solve_problem(ROBOT,problem,xs, us,maxiter = 50, STOP_THRESHOLD=1e-03, recalc_u=False, TYPE_OF_SOLVER='FDDP')\n",
    "traj = np.array(solver.xs)[:,0:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT = loadTalos('/opt/openrobots/share/example-robot-data')\n",
    "problem, xs, us, ts = define_croc_problem(ROBOT,'data_teguh_3.txt', num_phases=3, is_warmstart=False)\n",
    "clear_output()\n",
    "\n",
    "solver = solve_problem(ROBOT,problem,xs, us,maxiter = 50, STOP_THRESHOLD=1e-02, recalc_u=True, TYPE_OF_SOLVER='FDDP')\n",
    "traj2 = np.array(solver.xs)[:,0:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quick check\n",
    "#calc_foot_pose(traj[0], left_foot, right_foot)\n",
    "compare_phases_with_result(phases, np.array(solver.xs), left_foot, right_foot, viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between Coldstart and Warmstart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from croc_lib import *\n",
    "ROBOT = loadTalos('/opt/openrobots/share/example-robot-data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_phases_ori = []\n",
    "data_phases_ori.append(np.arange(0,1001))\n",
    "data_phases_ori.append(np.arange(1001,2361))\n",
    "data_phases_ori.append(np.arange(2361, 3351))\n",
    "\n",
    "viz.set_rate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'left'\n",
    "file_name = 'data.txt'\n",
    "\n",
    "result = dict()\n",
    "res_keys = ['gpr', 'gmr', 'gpr_A', 'gmr_A','cold', 'q', 'qu', 'q_nou', 'u']\n",
    "wm_methods = [gpr,gmr,gpr_A, gmr_A]\n",
    "#wm_methods = []\n",
    "for res_key in res_keys:\n",
    "    result[res_key] = dict()\n",
    "    result[res_key]['trajs'] = []\n",
    "    result[res_key]['vel_trajs'] = []\n",
    "    result[res_key]['u_trajs'] = []\n",
    "    \n",
    "    result[res_key]['n_iters'] = []\n",
    "    result[res_key]['costs'] = []\n",
    "    result[res_key]['x_inputs'] = []\n",
    "\n",
    "trajs_true = []\n",
    "    \n",
    "#for i in range(3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'right'\n",
    "tic = time.time()\n",
    "for i in range(len(x_inputs_test[key])):\n",
    "    print 'Iteration ' + str(i)\n",
    "    toc = time.time()\n",
    "    print 'Time so far: ' + str(toc-tic)\n",
    "    #create problem\n",
    "    #x_input,_ = gmm[key].sample()\n",
    "    x_input = x_inputs_test[key][i:i+1]\n",
    "    foot_marker.publish(x_input.reshape(-1,3))\n",
    "    w_pca_true = y_test[key][i]\n",
    "    w = pca[key].inverse_transform(w_pca_true)\n",
    "    w = w.reshape(rbf_num,-1)\n",
    "    traj_true = np.dot(Phi,w)\n",
    "    trajs_true.append(traj_true)\n",
    "    \n",
    "    \n",
    "    #viz.vis_traj(traj_true)\n",
    "    q_init = traj_true[0]\n",
    "    v_init = np.zeros(38)\n",
    "    \n",
    "    #warmstart method\n",
    "    for j, func in enumerate(wm_methods):\n",
    "        res_key = res_keys[j]\n",
    "        #predict the trajectory\n",
    "        w_pca,cov = func[key].predict(x_input)\n",
    "        w = func[key].pca.inverse_transform(w_pca)\n",
    "        w = w.reshape(rbf_num,-1)\n",
    "        traj = np.dot(Phi,w)\n",
    "\n",
    "        traj_mod,_ = convert_to_croc_format(x_input,traj,key, data_phases = data_phases_ori,\\\n",
    "                                q_init = q_init, v_init = v_init, filename=file_name)\n",
    "        print 'warmstart step' + res_key\n",
    "        problem, xs, us, ts = define_croc_problem(ROBOT,file_name, num_phases=3, is_warmstart=True)\n",
    "\n",
    "        solver = solve_problem(ROBOT,problem,xs, us,maxiter = 20, STOP_THRESHOLD=1e-02, recalc_u=True, TYPE_OF_SOLVER='FDDP')\n",
    "        traj = np.array(solver.xs)[:,0:39]\n",
    "        result[res_key]['trajs'] += [traj]\n",
    "        result[res_key]['n_iters'] += [solver.iter]\n",
    "        result[res_key]['costs'] += [solver.cost]\n",
    "        result[res_key]['x_inputs'] += [x_input]\n",
    "        \n",
    "    \n",
    "    print 'coldstart step'\n",
    "    problem, xs, us, ts = define_croc_problem(ROBOT,file_name, num_phases=3, is_warmstart=False)\n",
    "\n",
    "    solver = solve_problem(ROBOT,problem,xs, us,maxiter = 20, STOP_THRESHOLD=1e-02, recalc_u=True, TYPE_OF_SOLVER='FDDP')\n",
    "    traj = np.array(solver.xs)[:,0:39]\n",
    "    res_key = 'cold'\n",
    "    result[res_key]['trajs'] += [traj]\n",
    "    result[res_key]['n_iters'] += [solver.iter]\n",
    "    result[res_key]['costs'] += [solver.cost]\n",
    "    \n",
    "\n",
    "    \n",
    "    #predict the trajectories\n",
    "    w_pca,cov = gpr[key].predict(x_input)\n",
    "    w = gpr[key].pca.inverse_transform(w_pca)\n",
    "    w = w.reshape(rbf_num,-1)\n",
    "    traj = np.dot(Phi,w)\n",
    "\n",
    "    w_pca,cov = gpr_vel[key].predict(x_input)\n",
    "    w = gpr_vel[key].pca.inverse_transform(w_pca)\n",
    "    w = w.reshape(rbf_num,-1)\n",
    "    vel_traj = np.dot(Phi,w)\n",
    "\n",
    "    w_pca,cov = gpr_u[key].predict(x_input)\n",
    "    w = gpr_u[key].pca.inverse_transform(w_pca)\n",
    "    w = w.reshape(rbf_num,-1)\n",
    "    u_traj = np.dot(Phi,w)\n",
    "\n",
    "    \n",
    "    wm_comps = ['q', 'qu', 'q_nou', 'u']\n",
    "    for res_key in wm_comps:\n",
    "        if res_key == 'q':\n",
    "            inputs = [traj.copy(),None,None]\n",
    "            recalc = True\n",
    "        elif res_key == 'q_nou':\n",
    "            inputs = [traj.copy(),None,None]\n",
    "            recalc = False\n",
    "        elif res_key == 'qu':\n",
    "            inputs = [traj.copy(),None,u_traj]\n",
    "            recalc = False\n",
    "        elif res_key == 'qv':\n",
    "            inputs = [traj.copy(),vel_traj,None]\n",
    "            recalc = True\n",
    "        elif res_key == 'qvu':\n",
    "            inputs = [traj.copy(),vel_traj,u_traj]\n",
    "            recalc = False\n",
    "        elif res_key == 'u':\n",
    "            inputs = [traj.copy()*0,None,u_traj]\n",
    "            recalc = False\n",
    "            \n",
    "        \n",
    "        traj_mod,_ = convert_to_croc_format(x_input,traj=inputs[0], vel_traj = inputs[1], \\\n",
    "                                u_traj = inputs[2], key = key, data_phases = data_phases_ori,\\\n",
    "                                q_init = q_init, v_init = v_init, filename=file_name)\n",
    "        print 'warmstart step' + res_key\n",
    "        problem, xs, us, ts = define_croc_problem(ROBOT,file_name, num_phases=3, is_warmstart=True)\n",
    "\n",
    "        solver = solve_problem(ROBOT,problem,xs, us,maxiter = 20, STOP_THRESHOLD=1e-02, recalc_u=recalc, TYPE_OF_SOLVER='FDDP')\n",
    "        res_traj = np.array(solver.xs)[:,0:39]\n",
    "        result[res_key]['trajs'] += [res_traj]\n",
    "        result[res_key]['vel_trajs'] += [np.array(solver.xs)[:,39:]]\n",
    "        result[res_key]['u_trajs'] += [np.array(solver.us)]\n",
    "        result[res_key]['n_iters'] += [solver.iter]\n",
    "        result[res_key]['costs'] += [solver.cost]\n",
    "        result[res_key]['x_inputs'] += [x_input]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    clear_output()\n",
    "    success = dict()\n",
    "    for res_key in res_keys:\n",
    "        success[res_key] = np.array(result[res_key]['costs']) < 1e2\n",
    "        print\"{0} \\t & {1:.2f} & \\t {2:.2f} $\\\\pm${3:.2f} & \\t {4:.2f} $\\\\pm$ {5:.2f}\".format(res_key,  100.*np.sum(success[res_key])/(len(success[res_key])+.000001), np.mean(np.array(result[res_key]['costs'])[success[res_key]]), np.std(np.array(result[res_key]['costs'])[success[res_key]]), np.mean(np.array(result[res_key]['n_iters'])[success[res_key]]),np.std(np.array(result[res_key]['n_iters'])[success[res_key]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = dict()\n",
    "for res_key in res_keys:\n",
    "    success[res_key] = np.array(result[res_key]['costs']) < 1e2\n",
    "    print\"{0} \\t & {1:.2f} & \\t {2:.2f} $\\\\pm${3:.2f} & \\t {4:.2f} $\\\\pm$ {5:.2f}\".format(res_key,  100.*np.sum(success[res_key])/(len(success[res_key])+.000001), np.mean(np.array(result[res_key]['costs'])[success[res_key]]), np.std(np.array(result[res_key]['costs'])[success[res_key]]), np.mean(np.array(result[res_key]['n_iters'])[success[res_key]]),np.std(np.array(result[res_key]['n_iters'])[success[res_key]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(ROOT_CROCS + '/result_single_leftright.pkl', 'wb')\n",
    "pickle.dump(result,f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
